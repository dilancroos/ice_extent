{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part One : Arctic and Antarctic Ice Extent \n",
    "\n",
    "Analyzing the Ice Extent from 1979 to 2023 and plotting the  trend of ice extent over time. The Data is from 1978 - 2024,but we have removed 1978 and 2024 as there are only two months in 1978 and  one month in 2024 which makes it unsuitable for analysis.\n",
    "\n",
    "The below graphs is the goal to plot using the arctic and antarctic sea ice level, the data provided by NSIDC (National Snow and Ice Data Center) which is a part of the University of Colorado Boulder.\n",
    "\n",
    "We are interested in the columns: \"Year\", \"Month\", \"Day\", \"Extent\". The column \"Extent\" has values in million square kilometers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img.jpg\" alt=\"Sea Ice Index\" width=\"600\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation \n",
    "\n",
    "1. Dropping the Source Data column\n",
    "2. Dropping the first row (YYYY, MM, DD, 10^6 sq km\t10^6 sq km, \tSource data product web sites: http://nsidc.o...)  as it is not necessary for our analysis.\n",
    "3. Converting Year to a numerical data type (int)\n",
    "4. Group the DataFrame by the 'year' column.\n",
    "5. Calculate the mean of the 'Extent' column for each year.\n",
    "6. Reset the DataFrame index, Set the 'year' column as the new index.\n",
    "7. Changing the \"Year\", \"Month\", \"Day\" into date and time format\n",
    "\n",
    "\n",
    "### Link\n",
    "\n",
    "Arctic = https://noaadata.apps.nsidc.org/NOAA/G02135/north/daily/data/N_seaice_extent_daily_v3.0.csv\n",
    "\n",
    "\n",
    "Antarctic = https://noaadata.apps.nsidc.org/NOAA/G02135/south/daily/data/S_seaice_extent_daily_v3.0.csv\n",
    "\n",
    "\n",
    "# Team members \n",
    "\n",
    "### . Sayed Mossavi \n",
    "### . Dilan Croos\n",
    "### . Ranjani A V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Importing libraries \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Importing libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import watermark\n",
    "import requests\n",
    "import pathlib\n",
    "import zipfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Arctic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the data is not available, download it\n",
    "# if Datasets directory is not available, create it\n",
    "pathlib.Path(\"Datasets\").mkdir(exist_ok=True)\n",
    "\n",
    "# check the files in the Datasets directory\n",
    "path = pathlib.Path(\"Datasets\")\n",
    "files = [file.name for file in path.iterdir()]\n",
    "if \"N_seaice_extent_daily_v3.0.csv\" in files:\n",
    "    print(\"The data is available\")\n",
    "else:\n",
    "\n",
    "    # read the data\n",
    "    url = \"https://noaadata.apps.nsidc.org/NOAA/G02135/north/daily/data/N_seaice_extent_daily_v3.0.csv\"\n",
    "    r = requests.get(url)\n",
    "    with open(\"Datasets/N_seaice_extent_daily_v3.0.csv\", \"wb\") as f:\n",
    "        f.write(r.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data in csv format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data\n",
    "n_seaice = pd.read_csv('Datasets/N_seaice_extent_daily_v3.0.csv', header=0)\n",
    "n_seaice.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns name \n",
    "n_seaice.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping the [' Source Data'], and the first Row of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the Source Data colunm\n",
    "n_seaice_clean =(n_seaice\n",
    "                 .drop([' Source Data'], axis=1)\n",
    "                 .drop([0], axis=0)\n",
    "                 )\n",
    "n_seaice_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explor the data shape\n",
    "n_seaice_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the data set\n",
    "n_seaice_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the interested columns into integer format, since all the cols are in object format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Year, Month, Day, Missing and Extent columns to integers\n",
    "n_seaice_clean['Year'] = n_seaice_clean['Year'].astype(int)\n",
    "n_seaice_clean['Month'] = n_seaice_clean[' Month'].astype(int)\n",
    "n_seaice_clean['Day'] = n_seaice_clean[' Day'].astype(int)\n",
    "n_seaice_clean['Extent'] = n_seaice_clean['     Extent'].astype(float)\n",
    "n_seaice_clean['Missing'] = n_seaice_clean['    Missing'].astype(float)\n",
    "n_seaice_clean =(n_seaice_clean\n",
    "                 .drop([' Month'], axis=1)\n",
    "                 .drop([' Day'], axis=1)\n",
    "                 .drop(['     Extent'], axis=1)\n",
    "                 .drop(['    Missing'], axis=1)\n",
    "                 )\n",
    "n_seaice_clean['Date'] = pd.to_datetime(n_seaice_clean[['Year', 'Month', 'Day']])\n",
    "n_seaice_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the data afer converting the Year colunm to float and dropping unnecessary cols\n",
    "n_seaice_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Describtion \n",
    "n_seaice_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping  data by Year and get the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby year the data, and get the mean\n",
    "n_seaice_grouped = n_seaice_clean.groupby(['Year']).mean()\n",
    "n_seaice_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the min and max year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min & Max year \n",
    "yearMin = n_seaice_grouped.index.min()\n",
    "yearMax = n_seaice_grouped.index.max()\n",
    "print(yearMin)\n",
    "print(yearMax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping the min and max  (1978 & 2024), and the reason is explained in the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the first year and the last year\n",
    "n_seaice_grouped = n_seaice_grouped.drop([yearMin, yearMax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the arctic  sea ice extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_seaice_grouped['Extent'], label='Arctic Ics Extent')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Ice Extent')\n",
    "plt.title('Arctic Sea Ice Extent', fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add regression line\n",
    "# plot the data\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_seaice_grouped['Extent'], label='Arctic Ics Extent', color='black')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Ice Extent')\n",
    "plt.title('Arctic Sea Ice Extent', fontsize=20)\n",
    "plt.legend()\n",
    "\n",
    "# Add regression line\n",
    "z = np.polyfit(n_seaice_grouped.index, n_seaice_grouped['Extent'], 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(n_seaice_grouped.index, p(n_seaice_grouped.index), \"r-\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Antarctic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the data is not available, download it\n",
    "\n",
    "# check the files in the Datasets directory\n",
    "path = pathlib.Path(\"Datasets\")\n",
    "files = [file.name for file in path.iterdir()]\n",
    "if \"S_seaice_extent_daily_v3.0.csv\" in files:\n",
    "    print(\"The data is available\")\n",
    "else:\n",
    "    # read the data\n",
    "    url = \"https://noaadata.apps.nsidc.org/NOAA/G02135/south/daily/data/S_seaice_extent_daily_v3.0.csv\"\n",
    "    r = requests.get(url)\n",
    "    with open(\"Datasets/S_seaice_extent_daily_v3.0.csv\", \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_seaice = pd.read_csv ('Datasets/S_seaice_extent_daily_v3.0.csv', header=0)\n",
    "\n",
    "s_seaice.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the columns\n",
    "s_seaice.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping the [' Source Data'], and the first Row of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the cloumn (Soure Data)\n",
    "s_seaice_clean = (s_seaice\n",
    "                  .drop([' Source Data'], axis =1)\n",
    "                  .drop([0], axis=0))\n",
    "s_seaice_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the data\n",
    "s_seaice_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types of the data \n",
    "s_seaice_clean.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the interested columns into integer format, since all the cols are in object format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Year, Month and Day columns to integers\n",
    "s_seaice_clean['Year'] = s_seaice_clean['Year'].astype(int)\n",
    "s_seaice_clean['Month'] = s_seaice_clean[' Month'].astype(int)\n",
    "s_seaice_clean['Day'] = s_seaice_clean[' Day'].astype(int)\n",
    "s_seaice_clean['Extent'] = s_seaice_clean['     Extent'].astype(float)\n",
    "s_seaice_clean['Missing'] = s_seaice_clean['    Missing'].astype(float)\n",
    "s_seaice_clean =(s_seaice_clean\n",
    "                 .drop([' Month'], axis=1)\n",
    "                 .drop([' Day'], axis=1)\n",
    "                 .drop(['     Extent'], axis=1)\n",
    "                 .drop(['    Missing'], axis=1))\n",
    "s_seaice_clean['Date'] = pd.to_datetime(s_seaice_clean[['Year', 'Month', 'Day']])\n",
    "s_seaice_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping  data by Year and get the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_seaice_grouped = s_seaice_clean.groupby(['Year']).mean()\n",
    "s_seaice_grouped.tail() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the min and max year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearMin = s_seaice_grouped.index.min()\n",
    "yearMax = s_seaice_grouped.index.max()\n",
    "print(yearMin)\n",
    "print(yearMax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping the min and max  (1978 & 2024), and the reason is explained in the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 1978 and 2024\n",
    "s_seaice_grouped = s_seaice_grouped.drop([yearMin, yearMax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_seaice_grouped.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the arctic  sea ice extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the rolling mean of the sea ice extent\n",
    "\n",
    "# plot the data\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(s_seaice_grouped['Extent'], label='Antarctic Ics Extent')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Ice Extent')\n",
    "plt.title('Antarctic Sea Ice Extent', fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add regression line\n",
    "# plot the data\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(s_seaice_grouped['Extent'], label='Antarctic Ics Extent', color='black')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Ice Extent')\n",
    "plt.title('Antarctic Sea Ice Extent', fontsize=20)\n",
    "plt.legend()\n",
    "\n",
    "# Add regression line\n",
    "z = np.polyfit(s_seaice_grouped.index, s_seaice_grouped['Extent'], 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(s_seaice_grouped.index, p(s_seaice_grouped.index), \"r-\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting together the Arctic & Antarctic sea ice extent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the arctic and antarctic ice extent in one plot\n",
    "\n",
    "# plot the data\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(s_seaice_grouped['Extent'], label='Antarctic Ics Extent')\n",
    "plt.plot(n_seaice_grouped['Extent'], label='Arctic Ics Extent')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Ice Extent')\n",
    "plt.title('Sea Ice Extent', fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting together the Arctic & Antarctic sea ice extent, and adding the regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear regression line for Antarctic ice extent\n",
    "x_antarctic = np.arange(len(s_seaice_grouped['Extent']))\n",
    "y_antarctic = s_seaice_grouped['Extent']\n",
    "coefficients_antarctic = np.polyfit(x_antarctic, y_antarctic, 1)\n",
    "poly_line_antarctic = np.poly1d(coefficients_antarctic)\n",
    "\n",
    "# Fit a linear regression line for Arctic ice extent\n",
    "x_arctic = np.arange(len(n_seaice_grouped['Extent']))\n",
    "y_arctic = n_seaice_grouped['Extent']\n",
    "coefficients_arctic = np.polyfit(x_arctic, y_arctic, 1)\n",
    "poly_line_arctic = np.poly1d(coefficients_arctic)\n",
    "\n",
    "# Assuming you have already calculated y_antarctic and y_arctic\n",
    "# Plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Plot Antarctic sea ice extent and regression line\n",
    "plt.plot(s_seaice_grouped.index, y_antarctic, label='Antarctic Ice Extent')\n",
    "plt.plot(s_seaice_grouped.index, poly_line_antarctic(x_antarctic), label='Antarctic Regression Line', color='blue', linestyle='--')\n",
    "\n",
    "# Plot Arctic sea ice extent and regression line\n",
    "plt.plot(n_seaice_grouped.index, y_arctic, label='Arctic Ice Extent')\n",
    "plt.plot(n_seaice_grouped.index, poly_line_arctic(x_arctic), label='Arctic Regression Line', color='orange', linestyle='--')\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Ice Extent')\n",
    "plt.title('Sea Ice Extent', fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Two: Global Mean Sea Level\n",
    "\n",
    "The data for GMSL is from two sources:\n",
    "1. US Environmental Protection Agency, from 1880-2014. The data is monthly, instead of daily. It is recorded on the 15th of every month. The columns are: \"Time\", \"GMSL\".\n",
    "\n",
    "2. European Environment Agency, from 1993-2022. The data obtained is daily. The columns are: \"Year\", \"GSML\".\n",
    "\n",
    "We intend to observe the change in sea level over the years and evaluate the consistency of the the two data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the files in the Datasets directory\n",
    "path = pathlib.Path(\"Datasets\")\n",
    "files = [file.name for file in path.iterdir()]\n",
    "if \"sea-level-rise_zip.zip\" in files:\n",
    "    print(\"The data is available\")\n",
    "\n",
    "else:\n",
    "    # read the data\n",
    "    url = \"https://datahub.io/core/sea-level-rise/r/sea-level-rise_zip.zip\"\n",
    "    r = requests.get(url)\n",
    "    with open(\"Datasets/sea-level-rise_zip.zip\", \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "    # unzip the file\n",
    "    with zipfile.ZipFile(\"Datasets/sea-level-rise_zip.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"Datasets/sea-level-rise\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the sea level data\n",
    "\n",
    "sea_level = pd.read_csv('Datasets/sea-level-rise/data/csiro_alt_gmsl_mo_2015_csv.csv', header=0)\n",
    "sea_level.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_level.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the time column (Year)  to a date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the time column to datetime\n",
    "\n",
    "sea_level['Time'] = pd.to_datetime(sea_level['Time'])\n",
    "sea_level.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_level.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping the data by Time (Year) and getting the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by year and get the mean\n",
    "\n",
    "sea_level_grouped = sea_level.groupby(sea_level['Time'].dt.year).mean()\n",
    "sea_level_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_level_grouped['GMSL in cm'] = sea_level_grouped['GMSL'].apply(lambda x: x/10)\n",
    "sea_level_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Global Mean Sea Level  (GMSL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(sea_level_grouped['GMSL'], label='Sea Level Rise (mm)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Sea Level Rise (mm)')\n",
    "plt.title('Global Mean Sea Level', fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Arctic and Antarctic ice extent and the global mean sea level in one plot\n",
    "\n",
    "# plot the data\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(s_seaice_grouped['Extent'], label='Antarctic Ics Extent')\n",
    "plt.plot(n_seaice_grouped['Extent'], label='Arctic Ics Extent')\n",
    "# plt.plot(sea_level_grouped['GMSL in cm'], label='Sea Level Rise (cm)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Extent / Sea Level Rise (mm)')\n",
    "plt.title('Sea Ice Extent and Sea Level Rise', fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All graphs in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
